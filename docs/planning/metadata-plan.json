{
  "plan": "Gold-Standard Metadata & Camera Profile Framework",
  "version": "3.2",
  "status": "planning",
  "philosophy": "The app works on ANY video file from ANY source. Camera profiles ENHANCE the experience but never GATE it. A screen recording, a dashcam clip, a file downloaded off the internet -- they all import, play, and auto-edit. The profile system is additive polish, not a requirement.",

  "v3_corrections": {
    "summary": "v3.0 corrects 8 major discrepancies between the v2.1 plan and the actual codebase. These were found by auditing every file the plan references.",
    "corrections": [
      {
        "id": "C1",
        "issue": "TWO PARALLEL MATCHING SYSTEMS exist. Plan only referenced the legacy one.",
        "reality": "Legacy system: camera/mod.rs + camera/matcher.rs operates on Library DB camera_profiles table (no slugs, equal-weight scoring). Current system: ingest/mod.rs resolve_stable_camera_refs() + db/app_schema.rs operates on App DB bundled_profiles + user_profiles (HAS slugs, weighted scoring). The current system is the one used during ingest.",
        "fix": "All implementation steps now reference ingest/mod.rs as the primary matching entry point. Legacy camera/matcher.rs is noted as deprecated."
      },
      {
        "id": "C2",
        "issue": "Plan pointed at wrong fallback location.",
        "reality": "The actual fallback is at ingest/mod.rs:1271 in resolve_profile_from_app_db(), which returns ('none', ''). The plan said to change camera/matcher.rs.",
        "fix": "Step 1 now targets ingest/mod.rs:1271."
      },
      {
        "id": "C3",
        "issue": "Plan said to seed generic-fallback into canonical.json. Wrong source file.",
        "reality": "App DB system reads from bundled_profiles.json via sync_bundled_profiles() in app_schema.rs. canonical.json feeds the LEGACY Library DB system via camera/bundled.rs.",
        "fix": "Generic-fallback goes into bundled_profiles.json. canonical.json is the legacy source and is not the primary path."
      },
      {
        "id": "C4",
        "issue": "Plan proposed migration 12 to add profile_type/profile_ref to camera_devices. Already exists.",
        "reality": "App DB migration A1 already has: camera_devices.profile_type TEXT CHECK IN ('bundled','user','none') and camera_devices.profile_ref TEXT. These are the stable refs the plan wanted.",
        "fix": "Migration 12 removed. Step 8 no longer needs a migration. Only sample_exif_path column is genuinely missing (minor)."
      },
      {
        "id": "C5",
        "issue": "Plan says generic-fallback deinterlace='auto-detect' (string). TransformRules.deinterlace is Option<bool>.",
        "reality": "camera/mod.rs TransformRules has deinterlace: Option<bool>. Cannot hold a string. Also has deinterlace_mode: Option<String> for yadif/bwdif.",
        "fix": "Generic-fallback uses deinterlace=null (None) in Rust. The proxy generator interprets None as 'auto-detect from field_order'. This avoids a type change. The transform_rules JSON in bundled_profiles.json stores {\"deinterlace\": null, \"deinterlace_mode\": \"yadif\"} meaning: if the file needs deinterlacing (per field_order), use yadif."
      },
      {
        "id": "C6",
        "issue": "Plan proposed weighted scoring as new. Already exists.",
        "reality": "score_match_rules() at ingest/mod.rs:1336 already implements specificity weights: +5 make+model, +3 folderPattern, +3 codec+container, +2 resolution, +1 frameRate.",
        "fix": "Step 4 no longer proposes adding weighted scoring. Instead it adds reject rules (negative matching) and the audit trail, which are genuinely missing."
      },
      {
        "id": "C7",
        "issue": "Plan said consolidate to canonical.json as single source.",
        "reality": "The App DB system uses bundled_profiles.json. The legacy Library DB system uses canonical.json. These are two different files for two different systems.",
        "fix": "bundled_profiles.json is the primary source (App DB path). canonical.json remains for the legacy Library DB path. Step 5 consolidates by making bundled_profiles.json the single source of truth and updating the legacy path to read from the same file."
      },
      {
        "id": "C8",
        "issue": "Plan layer 4 schema gaps said camera_devices needs profile_slug and profile_type columns.",
        "reality": "App DB camera_devices already has profile_type and profile_ref columns (migration A1). Only sample_exif_path is genuinely missing.",
        "fix": "Layer 4 schema gaps section rewritten to reflect reality."
      }
    ]
  },

  "existing_code_reality": {
    "purpose": "Documents what ACTUALLY exists in the codebase. Every implementation step references this section to know what to change vs what to build new.",

    "matching_systems": {
      "current_system": {
        "description": "App DB matching system -- this is the one that runs during ingest",
        "entry_point": "ingest/mod.rs resolve_stable_camera_refs() line ~1159",
        "profile_source": "App DB bundled_profiles table (seeded from bundled_profiles.json) + user_profiles table",
        "device_source": "App DB camera_devices table",
        "matching_functions": [
          "resolve_profile_from_app_db() -- priority chain: user profiles > bundled profiles > legacy name > fallback ('none', '')",
          "match_app_profile_rules() -- scores user profiles, returns UUID of best match",
          "match_bundled_profile_rules() -- scores bundled profiles, returns slug of best match",
          "score_match_rules() -- weighted scoring: +5 make+model, +3 folderPattern, +3 codec+container, +2 resolution, +1 frameRate"
        ],
        "fallback": "('none', '') at ingest/mod.rs:1271 -- this is what we change to ('bundled', 'generic-fallback')",
        "device_matching": "resolve_stable_camera_refs() checks devices by USB fingerprint (find_device_by_usb_fingerprint_app), then serial (find_device_by_serial_app), then falls through to profile matching"
      },
      "legacy_system": {
        "description": "Library DB matching system -- deprecated, but code still exists",
        "entry_point": "camera/matcher.rs match_camera()",
        "profile_source": "Library DB camera_profiles table (seeded from canonical.json via camera/bundled.rs)",
        "what_it_does": "Equal-weight scoring (confidence = matches/total_rules), checks devices by integer profile_id",
        "status": "DEPRECATED. Still compiled. Not called during standard ingest. May be called from legacy code paths."
      }
    },

    "profile_sources": {
      "bundled_profiles_json": {
        "path": "resources/cameras/bundled_profiles.json",
        "feeds": "App DB bundled_profiles table via sync_bundled_profiles() in app_schema.rs",
        "format": "Array of {slug, name, version, match_rules, transform_rules}",
        "current_entries": 3,
        "profiles": ["sony-handycam-avchd", "canon-dslr", "panasonic-minidv"]
      },
      "canonical_json": {
        "path": "resources/cameras/canonical.json",
        "feeds": "Legacy Library DB camera_profiles table via camera/bundled.rs",
        "current_contents": "Empty array []",
        "status": "LEGACY. Not the primary path."
      }
    },

    "app_db_schema": {
      "bundled_profiles": "slug TEXT PK, name, version, match_rules JSON, transform_rules JSON, bundled_version",
      "user_profiles": "id, uuid TEXT UNIQUE, name, version, match_rules JSON, transform_rules JSON, created_at",
      "camera_devices": "id, uuid TEXT UNIQUE, profile_type TEXT CHECK IN ('bundled','user','none'), profile_ref TEXT, serial_number, fleet_label, usb_fingerprints JSON, rental_notes, created_at",
      "note": "camera_devices ALREADY has profile_type + profile_ref. No migration needed for stable refs."
    },

    "library_db_clips_columns": {
      "camera_profile_id": "INTEGER FK to legacy camera_profiles table (migration 1)",
      "camera_device_id": "INTEGER FK to legacy camera_devices table in Library DB (migration 5)",
      "camera_profile_type": "TEXT -- 'bundled', 'user', or NULL (migration 7)",
      "camera_profile_ref": "TEXT -- slug or UUID (migration 7)",
      "camera_device_uuid": "TEXT -- device UUID (migration 7)",
      "note": "Stable refs (migration 7) are the correct columns. Integer FKs are legacy."
    },

    "transform_rules_type": {
      "rust_struct": "camera/mod.rs TransformRules",
      "deinterlace": "Option<bool> -- true/false/None. Cannot hold string 'auto-detect'.",
      "deinterlace_mode": "Option<String> -- 'yadif', 'bwdif', etc.",
      "color_space": "Option<String>",
      "lut": "Option<String>",
      "interpretation": "deinterlace=None means auto-detect. deinterlace=Some(true) means always deinterlace. deinterlace=Some(false) means never deinterlace."
    },

    "sidecar_writer": {
      "file": "ingest/sidecar.rs",
      "write_method": "std::fs::write() -- NOT atomic. No temp file, no fsync.",
      "current_sections": ["original_file_path", "file_hash_blake3", "metadata_snapshot", "camera_match", "ingest_timestamps", "derived_asset_paths", "rental_audit"],
      "missing_sections": ["rawExifDump", "rawFfprobe", "extendedMetadata", "matchAudit"]
    },

    "exiftool_extraction": {
      "file": "metadata/exiftool.rs",
      "current_method": "Requests 9 specific tags with -TagName flags",
      "tags": ["DateTimeOriginal", "CreateDate", "MediaCreateDate", "Make", "Model", "SerialNumber", "InternalSerialNumber", "GPSLatitude", "GPSLongitude"],
      "needed": "Switch to exiftool -j -G -n for full dump"
    },

    "ffprobe_extraction": {
      "file": "metadata/ffprobe.rs",
      "current_fields": ["codec_type", "codec_name", "width", "height", "r_frame_rate", "channels", "sample_rate", "duration"],
      "missing_fields": ["field_order", "bits_per_raw_sample", "color_space", "color_primaries", "color_transfer", "display_aspect_ratio", "sample_aspect_ratio", "profile", "level"]
    }
  },

  "gold_standard_principles": {
    "summary": "Apply the same design patterns that made the import tool bulletproof: manifest completeness, two-tier verification, state machines, audit trails, fail-safe defaults, and crash recovery.",
    "principles": [
      {
        "name": "EVERY FILE GETS PROCESSED",
        "import_analog": "Every file in the source directory gets a manifest entry, even sidecars and orphans.",
        "metadata_application": "Every clip gets metadata extracted AND a profile assigned. Zero clips left in limbo. The generic fallback guarantees 100% coverage. There is no 'none' state."
      },
      {
        "name": "CAPTURE EVERYTHING, PARSE LATER",
        "import_analog": "Manifest records raw size + mtime before deciding what to do with the file.",
        "metadata_application": "Store the full raw exiftool and ffprobe dumps in the sidecar. Parse what we need today. When we need more fields tomorrow, re-parse from the stored dump -- never re-run the tools on the original file."
      },
      {
        "name": "TWO-TIER VERIFICATION",
        "import_analog": "Fast hash for dedup candidates, full hash for proof. Never trust fast hash alone.",
        "metadata_application": "Fast match (make+model) for profile candidates, full match (all rules + negative rules) for assignment. Never assign a profile on a single weak signal."
      },
      {
        "name": "AUDIT TRAIL FOR EVERY DECISION",
        "import_analog": "Every file gets a manifest entry with result, error_code, error_detail. You can reconstruct exactly what happened.",
        "metadata_application": "Every clip gets a matchAudit section in its sidecar: what metadata was available, what profiles were tested, what scores each got, why the winner won. You can reconstruct every matching decision without re-running anything."
      },
      {
        "name": "FAIL-SAFE DEFAULTS",
        "import_analog": "safe_to_wipe is NULL until ALL checks pass. One failure blocks the gate.",
        "metadata_application": "Generic fallback is SAFE. It auto-detects deinterlace and rotation from the file itself. It never applies a wrong color transform or LUT. Doing nothing wrong is better than guessing wrong."
      },
      {
        "name": "STATE MACHINE WITH RESUMABILITY",
        "import_analog": "Session status: discovering -> ingesting -> rescanning -> complete. Crash at any point, resume from last known state.",
        "metadata_application": "Metadata extraction status per clip: pending -> extracting -> extracted -> matching -> matched -> verified. If the app crashes mid-extraction, we know exactly which clips need reprocessing."
      },
      {
        "name": "IMMUTABLE BASELINE",
        "import_analog": "manifest_hash is computed once from the sorted file list. It's evidence of what existed at discovery time.",
        "metadata_application": "rawExifDump and rawFfprobe in the sidecar are the immutable baseline. They capture exactly what the tools reported at ingest time. All derived fields (sensor type, profile match) are computed FROM this baseline and can be recomputed."
      }
    ]
  },

  "architecture": {

    "layer_0_raw_dump_capture": {
      "purpose": "Capture the COMPLETE output of both extraction tools at ingest time. Store once, never re-run. This is the foundation everything else builds on.",
      "design": {
        "exiftool_command": "exiftool -j -G -n <file>",
        "exiftool_flags": {
          "-j": "JSON output",
          "-G": "Group names (e.g., EXIF:Make, QuickTime:CreateDate) -- disambiguates duplicate tag names across groups",
          "-n": "Numeric values (no human-readable formatting) -- gives raw numbers for GPS, focal length, etc."
        },
        "ffprobe_command": "ffprobe -v quiet -print_format json -show_format -show_streams -show_entries stream=field_order,bits_per_raw_sample,color_space,color_primaries,color_transfer,display_aspect_ratio,sample_aspect_ratio,profile,level <file>",
        "storage": "Both raw outputs stored in sidecar JSON as rawExifDump (object) and rawFfprobe (object). These are the immutable baseline.",
        "size_impact": "rawExifDump: 2-15KB per clip. rawFfprobe: 1-5KB per clip. For 10,000 clips that's 30-200MB in sidecars. Acceptable.",
        "extraction_validation": {
          "exiftool": "If exiftool returns exit code 0 and JSON parses successfully, extraction is valid. If exit code != 0 or JSON fails to parse, mark clip as extraction_failed with error detail. Do NOT block ingest -- clip still gets imported, just with incomplete metadata.",
          "ffprobe": "Same pattern. ffprobe failure means we have no duration/resolution/codec. Clip still imports. If exiftool succeeded, mark as extracted with partial data noted in sidecar extractionStatus section (see G7). If both tools failed, mark as extraction_failed."
        }
      },
      "states": {
        "pending": "Clip created, no extraction attempted yet",
        "extracting": "Tools are running (in-progress marker for crash recovery)",
        "extracted": "Both tools ran, raw dumps stored. May have partial data if one tool failed.",
        "extraction_failed": "Both tools failed. Clip has no metadata beyond filename and file size. Still imported."
      },
      "why_this_is_gold_standard": "The import tool captures size+mtime at discovery time as immutable evidence. This captures the full tool output as immutable evidence. When we decide next year that we need a field we didn't think of today, it's already in the dump. No re-extraction needed."
    },

    "layer_0b_outlier_media_handling": {
      "purpose": "Contract #4: audio-only and image files are ACCEPTED. The extraction pipeline must handle non-video media without treating it as an error. This layer defines how layers 0-2 behave for outlier types.",
      "contract_ref": "#3 (anything ffmpeg supports), #4 (audio-only and image files accepted, flagged as outlier)",

      "media_type_detection": {
        "method": "After ffprobe runs, classify by stream presence: video+audio = 'video', audio-only (no video stream) = 'audio', image (single video frame, no duration or duration=0) = 'image', unknown (ffprobe fails but exiftool succeeds) = 'unknown'",
        "db_column": "media_type TEXT CHECK (media_type IN ('video','audio','image')) -- on clips table (already exists from migration 1). Set during extraction (layer 0). Default 'video' for backwards compat. The value 'unknown' is NOT stored in the DB -- use 'video' as conservative default for unclassifiable files. The sidecar mediaType field can store 'unknown' since it's just JSON.",
        "sidecar_field": "mediaType in metadataSnapshot section"
      },

      "extraction_by_type": {
        "video": {
          "exiftool": "Full dump as normal",
          "ffprobe": "Full dump as normal -- has video + audio streams",
          "status": "extracted (normal path)"
        },
        "audio_only": {
          "exiftool": "Full dump -- exiftool reads MP3/WAV/M4A tags (artist, album, title, duration). Returns valid JSON.",
          "ffprobe": "Full dump -- returns audio stream only. No video stream. duration, sample_rate, channels, audio_codec are populated. Video fields (width, height, fps, codec, field_order) are null.",
          "status": "extracted (not extraction_failed -- having no video stream is expected, not an error)",
          "note": "The state machine must distinguish 'no video stream because audio-only' from 'no video stream because ffprobe failed'. media_type='audio' handles this."
        },
        "image": {
          "exiftool": "Full dump -- exiftool is strongest on images (EXIF, IPTC, XMP). Returns rich data: make, model, GPS, focal length, exposure, etc.",
          "ffprobe": "Full dump -- returns a single video stream with width/height but duration=0 or N/A. codec_name is 'mjpeg' or 'png' etc. No audio stream.",
          "status": "extracted",
          "note": "Images often have MORE exiftool data than video files. The raw dump is especially valuable here."
        },
        "unknown": {
          "exiftool": "May succeed or fail depending on file type",
          "ffprobe": "Failed or returned no usable streams",
          "status": "extraction_failed OR extracted (if exiftool alone succeeded)",
          "note": "File was still imported per contract #3. It just has minimal metadata."
        }
      },

      "parsed_fields_by_type": {
        "video": "All layer 1 fields apply as documented",
        "audio_only": {
          "populated": ["duration_ms", "audio_codec", "audio_channels", "audio_sample_rate", "bitrate", "container", "recorded_at (from exiftool tags)"],
          "null_and_expected": ["width", "height", "fps", "codec (video)", "field_order", "color_space", "display_aspect_ratio"],
          "note": "Null video fields are CORRECT, not missing. Do not mark as incomplete."
        },
        "image": {
          "populated": ["width", "height", "camera_make", "camera_model", "serial_number", "focal_length", "gps_latitude", "gps_longitude", "recorded_at", "color_space"],
          "null_and_expected": ["duration_ms (0 or null)", "fps", "audio_codec", "audio_channels", "field_order", "bitrate"],
          "note": "Images often have richer EXIF than video. camera_make/model matching works well for images."
        }
      },

      "profile_matching_for_outliers": {
        "audio_only": "Profile matching still runs. Most match_rules check video-centric fields (codec, resolution, folder_pattern) so audio files will score low on everything and land on generic-fallback. This is correct. Generic-fallback transform_rules for audio: passthrough (no deinterlace, no rotation, no color transform). Audio proxy: copy or transcode to m4a.",
        "image": "Profile matching runs. make+model rules CAN match images (a Canon DSLR photo matches 'canon-dslr' profile by make+model). This is useful -- it links the photo to the same camera as the video. Transform_rules for images: no deinterlace, no rotation correction needed (image viewers handle EXIF orientation), no color transform. Thumbnail: the image itself (resized).",
        "generic_fallback_for_outliers": "Generic fallback already does passthrough for anything it doesn't understand. Audio and image files get: no transforms applied, media_type flag set, appropriate proxy/thumbnail generation. No special transform_rules needed."
      },

      "proxy_generation_for_outliers": {
        "audio_only": "Proxy is an m4a transcode (or copy if already m4a/aac). No video proxy generated. Thumbnail is a waveform image or a generic audio icon. Sprite sheet: N/A.",
        "image": "Proxy is a resized JPEG (720p equivalent). Thumbnail is the image itself (resized). Sprite sheet: N/A (single frame).",
        "note": "Proxy generation must check media_type before assuming video pipeline. This is a code path branch in the proxy generator, not in the metadata plan, but the media_type field from this layer is what drives it."
      }
    },

    "layer_1_parsed_metadata": {
      "purpose": "Extract structured fields from the raw dumps. These are the values that go into the DB and drive the UI.",
      "fields_from_exiftool_dump": {
        "core": {
          "recorded_at": "DateTimeOriginal > CreateDate > MediaCreateDate (group-aware: prefer EXIF group over QuickTime group)",
          "camera_make": "EXIF:Make or QuickTime:Make",
          "camera_model": "EXIF:Model or QuickTime:Model",
          "serial_number": "EXIF:SerialNumber > EXIF:InternalSerialNumber > MakerNotes:SerialNumber"
        },
        "extended": {
          "sensor_type": "EXIF:ImageSensorType (direct, rare)",
          "focal_length": "EXIF:FocalLength (mm, numeric from -n flag)",
          "focal_length_35mm": "EXIF:FocalLengthIn35mmFormat (computed crop factor = focal_length_35mm / focal_length)",
          "scale_factor": "Composite:ScaleFactor35efl (direct crop factor)",
          "native_width": "EXIF:ExifImageWidth (sensor native, not output)",
          "native_height": "EXIF:ExifImageHeight",
          "bits_per_sample": "EXIF:BitsPerSample",
          "color_space": "EXIF:ColorSpace",
          "white_balance": "EXIF:WhiteBalance",
          "lens_model": "EXIF:LensModel",
          "lens_id": "EXIF:LensID",
          "megapixels": "Composite:Megapixels",
          "rotation": "Composite:Rotation or QuickTime:Rotation",
          "gps_latitude": "EXIF:GPSLatitude (already numeric from -n flag)",
          "gps_longitude": "EXIF:GPSLongitude",
          "compressor_id": "QuickTime:CompressorID"
        }
      },
      "fields_from_ffprobe_dump": {
        "core": {
          "duration_ms": "format.duration (seconds -> ms)",
          "width": "video stream width",
          "height": "video stream height",
          "fps": "video stream r_frame_rate (parse fraction)",
          "codec": "video stream codec_name",
          "audio_codec": "audio stream codec_name",
          "audio_channels": "audio stream channels",
          "audio_sample_rate": "audio stream sample_rate",
          "bitrate": "format.bit_rate",
          "container": "format.format_name",
          "creation_time": "format.tags.creation_time"
        },
        "extended": {
          "field_order": "video stream field_order (tt, bb, progressive, unknown)",
          "bits_per_raw_sample": "video stream bits_per_raw_sample",
          "color_space": "video stream color_space (bt709, bt601, bt2020, etc.)",
          "color_primaries": "video stream color_primaries",
          "color_transfer": "video stream color_transfer",
          "display_aspect_ratio": "video stream display_aspect_ratio",
          "sample_aspect_ratio": "video stream sample_aspect_ratio",
          "codec_profile": "video stream profile (Baseline, Main, High for H.264)",
          "codec_level": "video stream level"
        }
      },
      "storage": {
        "db_clips_table": "Core fields only. Same columns as today plus nothing new. DB stays lean.",
        "sidecar_metadata_snapshot": "Core + extended fields in metadataSnapshot section. This is the parsed, structured view.",
        "sidecar_extended_metadata": "Extended fields in extendedMetadata section for sensor/lens/color data."
      },
      "parsing_rules": {
        "null_is_fine": "Any field can be null. A clip with zero exiftool data still has ffprobe data. A clip with zero ffprobe data still has filename and size. There is always SOMETHING.",
        "group_disambiguation": "With -G flag, exiftool returns 'EXIF:Make' not just 'Make'. When the same tag exists in multiple groups (e.g., EXIF:CreateDate vs QuickTime:CreateDate), prefer EXIF group -- it's closer to the sensor.",
        "numeric_preference": "With -n flag, GPS returns decimal degrees directly. No DMS parsing needed. FocalLength returns mm as float. Cleaner than parsing human-readable strings."
      }
    },

    "layer_2_generic_fallback_profile": {
      "purpose": "The safety net. Every clip that doesn't match a specific profile gets this. It must produce CORRECT output for any video file thrown at it -- camcorder, phone, screen recording, dashcam, downloaded meme, anything.",
      "design": {
        "slug": "generic-fallback",
        "name": "Unknown Camera",
        "version": 1,
        "is_system": true,
        "deletable": false,
        "category": "system",
        "match_rules": "EMPTY OBJECT {}. This profile is NEVER matched by rules. It is assigned by the fallback branch in resolve_profile_from_app_db() when no other profile scores above threshold.",
        "transform_rules": {
          "deinterlace": {
            "rust_value": "null (None in Option<bool>)",
            "json_value": "null",
            "logic": "Proxy generator interprets deinterlace=null as auto-detect. Read ffprobe field_order from raw dump. If field_order is 'tt' or 'bb' -> deinterlace with yadif. If field_order is 'progressive' or missing -> do NOT deinterlace. Never guess.",
            "why": "Deinterlacing progressive footage creates artifacts. Not deinterlacing interlaced footage looks terrible. Auto-detect from the file itself is the only safe choice.",
            "type_note": "TransformRules.deinterlace is Option<bool>. We use None to mean auto-detect. No type change needed."
          },
          "deinterlace_mode": "yadif",
          "rotation": {
            "mode": "auto-detect",
            "logic": "Read rotation from exiftool Rotation tag or ffprobe side_data displaymatrix. If present, apply rotation correction. If absent, do nothing.",
            "why": "Phone footage is often recorded in portrait but played in landscape without rotation metadata applied. Respecting the tag fixes this silently."
          },
          "color_space": {
            "mode": "passthrough (null)",
            "logic": "Do NOT transform color. Pass through as-is.",
            "why": "Wrong color transform is worse than no color transform. Without knowing the source camera, we can't know if the footage is Rec.601 (old SD) or Rec.709 (HD) or Rec.2020 (HDR). Passthrough is always safe."
          },
          "lut": null,
          "audio": "passthrough"
        }
      },
      "what_makes_it_gold_standard": {
        "principle": "Do no harm. The generic profile's job is to make the clip watchable without making anything worse.",
        "auto_detect_from_file": "It reads the FILE, not a lookup table. field_order and rotation are per-file properties. This means it works on any video from any source -- even files that have no camera metadata at all.",
        "no_assumptions": "It doesn't assume codec, container, resolution, era, or sensor. It only acts on signals that are in the file itself.",
        "upgradeable": "When a matching profile is later found (user adds a profile, database is updated), clips can be re-matched and upgraded. The generic assignment is never permanent."
      },
      "implementation": {
        "seeding": "Add generic-fallback entry to bundled_profiles.json (NOT canonical.json). It will be synced to App DB via sync_bundled_profiles() on startup. Must be first entry in the array.",
        "fallback_change": "In ingest/mod.rs resolve_profile_from_app_db() line 1271, change ('none', '') to ('bundled', 'generic-fallback'). This is a one-line change.",
        "match_rules_json": "{} -- empty object. score_match_rules() returns 0.0 for empty objects, so this profile can never win by scoring. It only wins by being the fallback.",
        "transform_rules_json": "{\"deinterlace\": null, \"deinterlace_mode\": \"yadif\", \"color_space\": null, \"lut\": null}",
        "proxy_generation": "When proxy generator reads transform_rules and sees deinterlace=null, it checks the clip's ffprobe raw dump for field_order. This replaces the current code that only deinterlaces when a profile explicitly says deinterlace=true."
      }
    },

    "layer_3_camera_database": {
      "purpose": "Bundled profiles for known cameras. Enhances the experience with camera-specific transforms. Not required -- generic fallback handles everything the database doesn't cover.",
      "design_principles": {
        "verified_only": "No profile ships unverified. Every profile in the database has been tested against real sample files. The verification workflow below is mandatory.",
        "single_source": "bundled_profiles.json is the ONLY source for the App DB system. The legacy canonical.json/camera/bundled.rs path is deprecated. Step 5 consolidates to bundled_profiles.json.",
        "additive_value": "A profile must provide value BEYOND what generic-fallback already does. If a camera shoots progressive H.264 with correct rotation metadata, generic-fallback already handles it perfectly. The profile is only worth creating if it adds: specific deinterlace mode, field order override, color space correction, LUT, or known sensor info.",
        "negative_rules": "Profiles can REJECT matches to prevent false positives. Example: 'Canon DSLR' profile rejects container='3gp' (which would be Canon phone footage). This is critical for broad make-level profiles."
      },
      "profile_schema_v2": {
        "slug": "string -- stable forever (e.g., 'sony-hdr-cx405')",
        "name": "string -- display name, can change",
        "version": "integer -- bump when rules change",
        "verified": "boolean",
        "verified_sample": "string or null -- filename of sample used for verification",
        "category": "camcorder | dslr | mirrorless | action_cam | phone | capture_device | other",
        "era": "string -- e.g., '2007-2018'",
        "sensor": {
          "type": "CCD | CMOS | BSI-CMOS | Stacked-CMOS | null",
          "size": "string or null -- e.g., '1/5.8\"', 'APS-C', 'Full-Frame'",
          "megapixels": "number or null"
        },
        "match_rules": {
          "make": ["string array -- OR logic within, AND with other rules"],
          "model": ["string array -- substring match, case-insensitive"],
          "codec": ["string array"],
          "container": ["string array"],
          "folder_pattern": "regex string or null",
          "resolution": { "min_width": "int or null", "max_width": "int or null", "min_height": "int or null", "max_height": "int or null" },
          "frame_rates": ["number array -- tolerance +/- 0.5"],
          "compressor_id": ["string array"],
          "reject_codec": ["string array -- if clip has this codec, this profile does NOT match"],
          "reject_container": ["string array -- negative match"],
          "reject_model": ["string array -- if model contains this substring, reject (e.g., 'iPhone' to block phone footage from a Canon profile)"]
        },
        "transform_rules": {
          "deinterlace": "true | false | null (null = auto-detect from field_order)",
          "deinterlace_mode": "yadif | bwdif | null",
          "field_order": "tff | bff | auto | null",
          "color_space": "bt601 | bt709 | null",
          "lut": "path or null",
          "rotation_fix": "true | false"
        },
        "note_on_deinterlace_type": "In Rust, TransformRules.deinterlace is Option<bool>. JSON null -> None -> auto-detect. JSON true -> Some(true) -> always deinterlace. JSON false -> Some(false) -> never deinterlace. No type change needed."
      },
      "matching_algorithm_v2": {
        "existing_scoring": "score_match_rules() at ingest/mod.rs:1336 ALREADY implements weighted scoring: +5 make+model, +3 folderPattern, +3 codec+container, +2 resolution, +1 frameRate. This does NOT need to be rewritten.",
        "what_is_new": {
          "reject_rules": "Add reject_codec, reject_container, reject_model checks BEFORE scoring. If any reject rule matches, return 0.0 immediately. This is a new phase added before the existing scoring.",
          "minimum_threshold": "Add a minimum score threshold. If best candidate scores below 3.0 (weak match), use generic-fallback instead. Currently any score > 0.0 wins.",
          "audit_output": "Return all candidates with scores, not just the winner. Store in sidecar matchAudit section."
        },
        "phase_1_reject": "For each profile, check reject_codec, reject_container, reject_model. If ANY reject rule matches, skip this profile entirely.",
        "phase_2_score": "Run existing score_match_rules(). This already has weighted scoring.",
        "phase_3_threshold": "If best score < 3.0, use generic-fallback. Store all candidates in audit.",
        "confidence_meaning": {
          "1.0": "USB fingerprint match to registered device (layer 4)",
          "0.95": "Serial number match to registered device",
          "0.8_to_0.95": "Make + model + strong secondary signals (codec, resolution, folder)",
          "0.5_to_0.8": "Make or model + some secondary signals. Assigned but noted as partial match.",
          "below_0.5": "Too weak. Generic fallback assigned. Candidate recorded in audit trail for future profile improvement.",
          "0.1": "Generic fallback (no candidates scored above threshold)"
        }
      },
      "starter_profiles": {
        "note": "These are the initial profiles to build and verify. Ordered by likelihood of appearing in dad cam footage.",
        "tier_1_most_common": [
          "sony-handycam-avchd -- 1080i AVCHD, needs deinterlace+field order. Massive dad cam population.",
          "iphone-h264 -- Progressive H.264 MOV. No transforms needed but sensor/model info is valuable.",
          "iphone-hevc -- HEVC MOV. Same as above but codec differs.",
          "canon-vixia-hf -- Canon consumer camcorder line. AVCHD or MP4.",
          "panasonic-hc-v-series -- Panasonic consumer camcorder. AVCHD.",
          "dv-tape-generic -- Any dvvideo codec. Needs deinterlace. Catches all MiniDV regardless of brand.",
          "gopro-hero-h264 -- GoPro H.264 MP4. Progressive, wide-angle."
        ],
        "tier_2_common": [
          "sony-hdr-cx-series -- Specific Sony camcorder subline",
          "canon-dslr-h264 -- Canon DSLR video mode",
          "nikon-dslr -- Nikon DSLR video mode",
          "jvc-everio-avchd -- JVC consumer camcorder",
          "android-generic -- Android phone footage (various codecs)",
          "gopro-hero-hevc -- GoPro HEVC era",
          "dji-phantom-mavic -- Drone footage"
        ],
        "tier_3_legacy": [
          "sony-dcr-dvd -- Sony DVD camcorders (MPEG-2 VOB)",
          "sony-dcr-trv-minidv -- Sony Digital8/MiniDV",
          "canon-zr-minidv -- Canon MiniDV camcorders",
          "jvc-gr-minidv -- JVC MiniDV",
          "panasonic-minidv -- Panasonic MiniDV",
          "samsung-hmx -- Samsung consumer camcorder",
          "flip-video -- Flip Video pocket cams",
          "kodak-zi-playsport -- Kodak pocket cams"
        ],
        "tier_4_digitized_analog": [
          "vhs-c-digitized -- VHS-C captured via USB capture card. MPEG-2 or raw. Needs deinterlace.",
          "hi8-digitized -- Hi8/Digital8 captured. Similar to VHS-C.",
          "composite-capture-generic -- Any analog capture (RCA/S-Video input to capture device)"
        ]
      },
      "verification_workflow": {
        "per_profile": [
          "1. Obtain 1-3 sample files from the target camera. Real files, not transcodes.",
          "2. Run: exiftool -j -G -n sample.mp4 > sample.exif.json",
          "3. Run: ffprobe -v quiet -print_format json -show_format -show_streams sample.mp4 > sample.ffprobe.json",
          "4. Write match_rules from the dumps. Identify the MINIMUM set of rules that uniquely match this camera.",
          "5. Write reject rules: what OTHER cameras share similar metadata? Add reject_* rules to prevent those false positives.",
          "6. Test: run the matcher against the sample. Confirm the profile wins with score >= 3.0.",
          "7. Cross-test: run the matcher against samples from 5+ OTHER cameras. Confirm this profile does NOT match them.",
          "8. Determine transform_rules: play the original in ffplay. Does it need deinterlace? Check field_order. Does color look wrong? Check color_primaries. Record findings.",
          "9. Test proxy generation with the transform_rules. Compare output quality to VLC playback of original.",
          "10. Set verified=true, record sample filename, commit."
        ],
        "cross_validation": "When adding a new profile, re-run ALL existing profiles' cross-tests against the new sample. Ensures no existing profile is broken by the new addition.",
        "sample_storage": "Store verification samples in test-library/ (already gitignored). NOT in resources/ (too large for app bundle). Reference sample filename in profile's verified_sample field."
      }
    },

    "layer_4_registered_cameras": {
      "purpose": "Physical camera units registered by pro/rental users. Highest match priority. Already designed in pro-register-camera.md. This section documents the FULL FLOW: USB plug-in through database storage through backflow to existing clips.",

      "current_code_state": {
        "what_exists": [
          "CameraDevice struct (devices.rs): id, uuid, profile_id, serial_number, fleet_label, usb_fingerprints, rental_notes, created_at",
          "App DB camera_devices table (migration A1): profile_type TEXT CHECK IN ('bundled','user','none'), profile_ref TEXT -- STABLE REFS ALREADY EXIST",
          "insert_device() -- creates device record in App DB camera_devices table",
          "find_device_by_usb_fingerprint_app() -- App DB device lookup by USB fingerprint",
          "find_device_by_serial_app() -- App DB device lookup by serial number",
          "capture_usb_fingerprint() -- cross-platform (macOS system_profiler -xml, Windows Get-CimInstance, Linux /sys/bus/usb/devices/)",
          "save_devices_to_json() / load_devices_from_json() -- export/import to ~/.dadcam/custom_cameras.json",
          "resolve_stable_camera_refs() in ingest/mod.rs -- checks devices by USB fingerprint then serial BEFORE profile matching",
          "Library DB clips columns: camera_profile_type, camera_profile_ref, camera_device_uuid (migration 7)"
        ],
        "what_is_missing": [
          "No EXIF dump during registration (pro-register-camera.md specifies it but not implemented)",
          "No auto-profile assignment from EXIF data during registration",
          "No backflow: registering a device does NOT re-match existing clips",
          "No sample_exif_path column on camera_devices (minor -- for storing registration dump path)"
        ]
      },

      "registration_flow": {
        "summary": "User plugs in camera via USB (or inserts memory card). App detects device, dumps EXIF from sample files, auto-matches to a profile, and stores the registered device with all identifiers.",
        "steps": [
          {
            "step": "R1. USB Detection",
            "trigger": "User opens Dev Menu > Register Camera > Via USB (or auto-detect on plug-in if feature enabled)",
            "action": "Call capture_usb_fingerprint(). Returns list of vendor:product pairs and serial:XXX strings.",
            "output": "usb_fingerprints: ['0x054c:0x0b8c', 'serial:E35982']",
            "existing_code": "devices.rs capture_usb_fingerprint() -- already implemented for macOS/Windows/Linux",
            "gap": "None. This works today."
          },
          {
            "step": "R2. Mount + Sample Discovery",
            "trigger": "USB device detected or memory card mounted",
            "action": "Scan mounted volume for video files. Pick 1-3 representative samples (prefer largest file, or first file in DCIM/AVCHD structure).",
            "output": "sample_paths: ['/Volumes/CAMERA_SD/AVCHD/BDMV/STREAM/00001.mts']",
            "existing_code": "discover.rs file discovery logic can be reused",
            "gap": "Need new function: discover_sample_files(mount_point) that returns a small set of representative files without walking the entire tree."
          },
          {
            "step": "R3. Full EXIF + FFprobe Dump on Samples",
            "trigger": "Sample files found",
            "action": "Run exiftool -j -G -n AND ffprobe on each sample. Capture full raw dumps. This is the SAME extraction used during ingest (layer 0), reused here.",
            "output": "For each sample: { rawExifDump: {...}, rawFfprobe: {...}, parsedMetadata: {...} }",
            "existing_code": "metadata/exiftool.rs and metadata/ffprobe.rs -- need to switch to full dump mode (layer 0 change)",
            "gap": "Current exiftool.rs requests only 9 tags. Layer 0 changes this to full dump. Registration flow benefits from the same change."
          },
          {
            "step": "R4. Auto-Profile Matching",
            "trigger": "Parsed metadata available from samples",
            "action": "Run the matching algorithm against the parsed metadata. Use match_bundled_profile_rules() and match_app_profile_rules() from ingest/mod.rs.",
            "output": "matchResult: { winner: 'sony-handycam-avchd', confidence: 0.85, candidates: [...] }",
            "existing_code": "ingest/mod.rs match_bundled_profile_rules() + match_app_profile_rules() -- already accept profiles + metadata as input. These are the right functions.",
            "gap": "These functions don't return candidates/scores, only the winner slug. Need to extend to return all candidates for the registration UI."
          },
          {
            "step": "R5. Registration Form (UI)",
            "trigger": "Auto-fill data ready",
            "action": "Present the registration form pre-filled with: make, model, serial (from EXIF), USB fingerprints (from R1), suggested profile (from R4). User reviews, edits fleet_label/notes, confirms.",
            "output": "NewCameraDevice { profile_type, profile_ref, serial_number, fleet_label, usb_fingerprints, rental_notes }",
            "existing_code": "devices.rs NewCameraDevice struct -- already has the right fields",
            "gap": "UI not built yet. The auto-fill from EXIF is new."
          },
          {
            "step": "R6. Device Insert + Profile Assignment",
            "trigger": "User clicks 'Save Camera'",
            "action": "Call insert_device(). Store profile_type ('bundled' or 'user') and profile_ref (slug or UUID) from auto-match or user selection. If no profile matched, store profile_type='none', profile_ref=''.",
            "output": "CameraDevice record in App DB camera_devices table with stable profile refs",
            "existing_code": "devices.rs insert_device() + App DB camera_devices already has profile_type + profile_ref columns (migration A1)",
            "gap": "insert_device() may need to be updated to write profile_type/profile_ref. Currently may write to legacy profile_id instead."
          },
          {
            "step": "R7. JSON Backup Export",
            "trigger": "After successful insert",
            "action": "Call save_devices_to_json() to write ~/.dadcam/custom_cameras.json as backup.",
            "output": "JSON file with all registered devices",
            "existing_code": "devices.rs save_devices_to_json() -- works today",
            "gap": "None."
          },
          {
            "step": "R8. EXIF Registration Dump Storage",
            "trigger": "After successful insert",
            "action": "Store the full EXIF + FFprobe dumps from sample files alongside the device record. This is the evidence for the profile assignment and enables future re-matching.",
            "output": "~/.dadcam/device_dumps/<device_uuid>.json containing raw dumps from samples",
            "existing_code": "Nothing -- new",
            "gap": "New storage location and format. Same principle as sidecar raw dumps (layer 0) but for devices instead of clips."
          }
        ]
      },

      "backflow_to_existing_clips": {
        "summary": "When a new device is registered, re-check all existing clips that might belong to this camera. This is the CRITICAL connection between registration and the library.",
        "trigger": "After R6 (device saved to DB). Also on demand from Dev Menu > Re-match Clips.",
        "flow": [
          {
            "step": "B1. Identify Candidate Clips",
            "action": "Query all clips in all open libraries where camera_device_uuid IS NULL (not yet assigned to any device).",
            "query": "SELECT id, camera_profile_ref, camera_make, camera_model, serial_number FROM clips WHERE camera_device_uuid IS NULL OR camera_device_uuid = ''",
            "note": "We check ALL unassigned clips, not just generic-fallback ones. A clip might have a bundled profile match but no device assignment."
          },
          {
            "step": "B2. Match by Serial Number",
            "action": "For the newly registered device, check its serial_number against clip metadata. If device.serial_number matches clip's serial_number (from exiftool extraction), this clip came from this camera.",
            "confidence": "0.95",
            "query": "From B1 results, filter WHERE serial_number = device.serial_number",
            "note": "Serial comes from EXIF:SerialNumber or EXIF:InternalSerialNumber captured during ingest. If ingest didn't capture serial (old pipeline before layer 0), this won't match -- that's fine, other methods below."
          },
          {
            "step": "B3. Match by Make + Model + Profile",
            "action": "If device has an assigned profile with make+model rules, check if clip's camera_make+camera_model match those rules.",
            "confidence": "0.6 -- weaker because multiple units of the same model exist",
            "note": "This is a SOFT match. It says 'this clip COULD be from this camera model, but we can't prove which physical unit.' Still useful for grouping. User can confirm or reject."
          },
          {
            "step": "B4. Match by USB Fingerprint (ingest session)",
            "action": "Check ingest_sessions for this clip's ingest job. If the ingest session has device_serial or device_mount_point that matches the registered device's USB fingerprints, the clip was ingested from this device.",
            "confidence": "0.90",
            "query": "JOIN clips -> ingest_files/manifest_entries -> ingest_sessions WHERE device_serial matches any of device.usb_fingerprints",
            "note": "This works when the user ingested footage from the camera BEFORE registering it. The ingest session captured the USB fingerprint at ingest time. Now we can retroactively link it."
          },
          {
            "step": "B5. Apply Matches",
            "action": "For each matched clip, update: clips.camera_device_uuid = device.uuid. If the device has an assigned profile AND the clip's current profile is generic-fallback, ALSO upgrade the profile: clips.camera_profile_type = device.profile_type, clips.camera_profile_ref = device.profile_ref.",
            "atomicity": "All updates for a single device registration in one transaction. If any update fails, roll back all.",
            "sidecar_update": "Re-write the clip's sidecar with updated cameraMatch section. Use atomic sidecar write (layer 7). Also re-run matchAudit to record the device match.",
            "proxy_invalidation": "If profile changed (was generic, now specific with different transform_rules), set the proxy asset's pipeline_version = 0 to mark it stale. Do NOT delete the proxy -- the old proxy remains playable until the new one is regenerated. Next access (or background job) regenerates with correct transforms."
          },
          {
            "step": "B6. Report Results",
            "action": "Return to UI: 'Registered Sony HDR-CX405 (Rental Unit #7). Found 47 clips from this camera: 12 matched by serial number (high confidence), 35 matched by camera model (needs confirmation).'",
            "user_action": "User can review the model-matched clips and confirm/reject assignments. Serial-matched clips are auto-assigned (high confidence)."
          }
        ],
        "backflow_on_profile_add": {
          "trigger": "When bundled_profiles.json is updated with new profiles (app update or manual import)",
          "action": "Check all registered devices that have profile_type='none'. Re-run profile matching against the device's stored EXIF dump (from R8). If a new profile matches, offer to assign it to the device AND backflow to all clips from that device.",
          "flow": "Same as B1-B6 but triggered by profile addition instead of device registration."
        },
        "backflow_on_re_match": {
          "trigger": "User clicks 'Re-match All Clips' in settings or Dev Menu",
          "action": "Re-run the full matching algorithm on every clip using stored inputSignature from matchAudit (layer 5). Check devices first (highest priority), then bundled profiles, then generic fallback. Update any clips that now have better matches.",
          "note": "This is the layer 8 re-matching job. It covers both device-based and profile-based improvements."
        }
      },

      "forward_flow_during_ingest": {
        "summary": "When importing NEW footage, check registered devices FIRST. This is the forward path (device already registered, footage coming in now).",
        "flow": [
          {
            "step": "F1. Capture USB fingerprint at ingest start",
            "action": "If ingesting from a mounted volume, call capture_usb_fingerprint() and store in ingest_sessions.device_serial / device_mount_point.",
            "existing_code": "Already captured in ingest session (migration 9). Used for safe-to-wipe tracking.",
            "note": "This data is already there. We just need to USE it for matching."
          },
          {
            "step": "F2. Check registered devices BEFORE profile matching",
            "action": "In resolve_stable_camera_refs(), the current code already checks devices first (USB fingerprint via find_device_by_usb_fingerprint_app, then serial via find_device_by_serial_app). This is the correct priority order.",
            "existing_code": "ingest/mod.rs resolve_stable_camera_refs() -- already implemented",
            "gap": "Need to verify device lookup returns profile_type + profile_ref and that these are stored on the clip."
          },
          {
            "step": "F3. Store stable refs on clip",
            "action": "When a device match is found, store: camera_device_uuid = device.uuid, camera_profile_type = device.profile_type, camera_profile_ref = device.profile_ref. If device has profile_type='none', fall through to profile matching.",
            "existing_code": "Partial -- resolve_stable_camera_refs() already sets camera_device_uuid. Need to verify it also sets profile type/ref from device.",
            "gap": "The bridge between device.profile_type/profile_ref and clip.camera_profile_type/ref may not be fully wired."
          },
          {
            "step": "F4. Write to sidecar with device context",
            "action": "Sidecar cameraMatch section includes: deviceUuid, profileType, profileRef. matchAudit records that the match came from a registered device, not profile rules.",
            "existing_code": "sidecar.rs writes cameraMatch but doesn't distinguish device match from profile match",
            "gap": "Add matchSource field to sidecar: 'registered_device_usb', 'registered_device_serial', 'registered_device_model', 'bundled_profile', 'generic_fallback'"
          }
        ]
      },

      "database_schema_gaps": {
        "camera_devices_table": {
          "profile_type": "ALREADY EXISTS in App DB migration A1. CHECK IN ('bundled','user','none').",
          "profile_ref": "ALREADY EXISTS in App DB migration A1. Stores slug or UUID.",
          "sample_exif_path": "MISSING. Needed for R8 (registration dump storage). Minor addition.",
          "migration_needed": "Optional migration to add sample_exif_path. OR store the dump at a conventional path (~/.dadcam/device_dumps/<uuid>.json) and skip the column."
        },
        "no_migration_12_needed": "v2.1 plan proposed migration 12. This is WRONG. profile_type and profile_ref already exist on camera_devices in App DB. The Library DB's camera_devices (migration 5) is the legacy one, but we don't use it for the primary path."
      },

      "match_priority_chain": [
        "1. Registered device by USB fingerprint (ingest session fingerprint matches device.usb_fingerprints) -> confidence 1.0, assigns device + device's profile",
        "2. Registered device by serial number (clip exiftool serial matches device.serial_number) -> confidence 0.95, assigns device + device's profile",
        "3. Registered device by make+model (clip make+model matches device's assigned profile rules) -> confidence 0.6-0.8, suggests device (user confirms)",
        "4. Bundled profile from bundled_profiles.json (scoring algorithm, no device) -> confidence varies by rule strength",
        "5. Generic fallback (always succeeds) -> confidence 0.1, auto-detect transforms from file"
      ],

      "the_complete_lifecycle": {
        "scenario": "User buys 5 Sony HDR-CX405 camcorders for rental fleet. Over 6 months, clients return footage.",
        "timeline": [
          "Month 1: User imports footage from first client. No cameras registered yet. Clips match 'sony-handycam-avchd' bundled profile (make=Sony + codec=h264 + folder=AVCHD). Confidence 0.85. Profile applied. Clips get deinterlaced. Good.",
          "Month 2: User registers all 5 cameras via USB in Dev Menu. Each gets a UUID, serial, USB fingerprint, fleet label ('Rental #1' through '#5'). Profile auto-assigned to 'sony-handycam-avchd' via profile_type='bundled', profile_ref='sony-handycam-avchd'.",
          "Month 2 (backflow): App scans existing clips. 47 clips from Month 1 have serial numbers matching Rental #3. Those clips get camera_device_uuid assigned. Their profile was already correct (sony-handycam-avchd) so no proxy regeneration needed. But now they show 'Shot on: Rental #3' in the UI.",
          "Month 3: New client returns footage. During ingest, USB fingerprint matches Rental #1. All clips auto-assigned to Rental #1 with sony-handycam-avchd profile. 100% confidence. Zero user interaction.",
          "Month 4: User adds a custom LUT for the CX405. Creates a user profile 'sony-cx405-rental-lut' with the LUT path. Assigns it to all 5 devices (profile_type='user', profile_ref=<uuid>). Backflow triggers: all clips from these devices get profile upgraded. Proxies invalidated and regenerated with LUT applied.",
          "Month 6: User imports footage from a client's personal Canon camcorder (not registered). No device match. Bundled profile 'canon-vixia-hf' matches. Clips get correct transforms. Device stays unassigned -- this is someone else's camera, not fleet inventory."
        ]
      }
    },

    "layer_5_match_audit_trail": {
      "purpose": "Full audit trail for every matching decision. Same principle as the import manifest -- you can reconstruct exactly what happened without re-running anything.",
      "sidecar_section": {
        "name": "matchAudit",
        "structure": {
          "matchedAt": "ISO8601 -- when matching ran",
          "matcherVersion": "integer -- so we know which algorithm produced this result",
          "matchSource": "string -- 'registered_device_usb', 'registered_device_serial', 'bundled_profile', 'generic_fallback'",
          "inputSignature": {
            "purpose": "The EXACT metadata values that were fed into the matcher. Captured from the parsed fields, not the raw dump. This is the matcher's input -- frozen.",
            "fields": {
              "make": "string or null",
              "model": "string or null",
              "serial": "string or null",
              "codec": "string or null",
              "container": "string or null",
              "width": "int or null",
              "height": "int or null",
              "fps": "float or null",
              "fieldOrder": "string or null",
              "compressorId": "string or null",
              "folderPath": "string"
            }
          },
          "candidates": {
            "purpose": "Every profile that was evaluated, with its score breakdown. Not just the winner.",
            "entry": {
              "slug": "profile slug",
              "score": "float",
              "rejected": "bool -- true if a reject rule fired",
              "rejectReason": "string or null -- which reject rule fired",
              "matchedRules": ["list of rules that hit"],
              "failedRules": ["list of rules that were specified but didn't match"],
              "missingData": ["list of rules that couldn't be evaluated because metadata was absent"]
            }
          },
          "winner": {
            "slug": "winning profile slug or 'generic-fallback'",
            "confidence": "float",
            "assignmentReason": "string -- human-readable explanation"
          }
        }
      },
      "enables": {
        "re_match_on_profile_add": "When bundled_profiles.json is updated, scan all clips where winner.slug='generic-fallback'. Re-run matching using stored inputSignature (no file access needed). Upgrade clips that now match.",
        "profile_discovery": "Query: group all generic-fallback clips by inputSignature.make+model. Returns: 'You have 47 clips from JVC GZ-MG330 with no profile. Want to create one?' This drives organic database growth.",
        "false_positive_debug": "User reports wrong camera match. Look at matchAudit.candidates to see all scores. Identify which rule caused the false positive. Add a reject rule to the offending profile.",
        "matcher_version_tracking": "When we improve the matching algorithm, matcherVersion tells us which clips were matched with the old algorithm. We can selectively re-match only those clips."
      }
    },

    "layer_6_metadata_extraction_state_machine": {
      "purpose": "Track the metadata extraction and matching pipeline per clip, same way the import tracks per-file copy/verify state. Enables crash recovery and completeness verification.",
      "states": {
        "transition_diagram": "pending -> extracting -> extracted -> matching -> matched -> verified. extracting can also -> extraction_failed. matching can also -> extraction_failed.",
        "pending": "Clip record created in DB. No metadata extraction attempted.",
        "extracting": "exiftool and/or ffprobe are running. If app crashes here, we know to retry on next launch.",
        "extracted": "Raw dumps captured and stored in sidecar. Parsed fields populated in DB. May be partial (one tool failed).",
        "matching": "Camera matcher is evaluating this clip against profiles.",
        "matched": "Profile assigned. matchAudit written to sidecar.",
        "verified": "All metadata fields cross-checked. Sidecar written atomically. Terminal state.",
        "extraction_failed": "Both tools failed. Clip still imported with filename/size only. Can retry later."
      },
      "db_columns": {
        "metadata_status": {
          "name": "metadata_status",
          "table": "clips",
          "type": "TEXT CHECK (metadata_status IN ('pending','extracting','extracted','matching','matched','verified','extraction_failed'))",
          "default": "'verified' (migration DEFAULT -- backfills all existing clips as verified). New clips set to 'pending' by application code at insert time.",
          "migration": "New migration 11. ALTER TABLE uses DEFAULT 'verified' so all existing rows are backfilled. App code explicitly sets 'pending' when inserting new clips."
        },
        "media_type": {
          "name": "media_type",
          "table": "clips",
          "type": "TEXT CHECK (media_type IN ('video','audio','image'))",
          "default": "'video'",
          "migration": "Already exists from migration 1. No change needed. The value 'unknown' is NOT stored in the DB -- use 'video' as conservative default for unclassifiable files. Sidecar mediaType field can store 'unknown' since it's just JSON.",
          "note": "This column drives proxy generation branching and prevents audio-only/image files from being treated as extraction failures."
        }
      },
      "crash_recovery": {
        "on_app_launch": "Query clips WHERE metadata_status IN ('extracting', 'matching'). These crashed mid-pipeline. Reset to 'pending' and re-queue.",
        "on_ingest_complete": "Query clips WHERE metadata_status != 'verified' AND metadata_status != 'extraction_failed' for this ingest session. If any exist, session is NOT fully processed."
      },
      "completeness_gate": {
        "purpose": "Same as safe_to_wipe but for metadata. An ingest session is only 'metadata_complete' when ALL clips are in terminal state (verified or extraction_failed).",
        "implementation": "Add metadata_complete_at column to ingest_sessions. Set when all clips from that session reach terminal state. NULL until then.",
        "relationship_to_safe_to_wipe": "metadata_complete_at is NOT a prerequisite for SAFE TO WIPE. SAFE TO WIPE is gated solely by the import pipeline (all manifest entries verified + rescan diff empty). Metadata extraction can still be in progress or failed and SAFE TO WIPE can still be true -- the bytes are safely copied regardless of whether we parsed them yet. metadata_complete_at is a separate completeness signal for the UI (e.g., 'Metadata processing: 847/850 clips done') and for the re-matching job (don't re-match a session that hasn't finished initial matching)."
      },
      "reference_mode": {
        "purpose": "In reference-mode imports (ingest_mode='reference'), files are NOT copied -- the library points to original file locations. The metadata extraction pipeline still runs.",
        "layer_0_behavior": "Raw dump capture (exiftool + ffprobe) runs against the original file path. The file must be accessible (drive mounted). If the drive is disconnected, extraction fails gracefully and clip gets metadata_status='extraction_failed'. Re-extraction can run later when the drive is reconnected.",
        "layer_1_through_5_behavior": "Parsing, matching, audit trail, and state machine all work identically to copy-mode. The metadata pipeline does not care whether the file was copied or referenced.",
        "sidecar_behavior": "App-generated sidecars (.dadcam/sidecars/*.json) are written to the library's sidecar directory as normal. These are app-side artifacts, not source-device files, so reference mode does not affect them.",
        "safe_to_wipe": "SAFE TO WIPE is NOT offered for reference-mode sessions (nothing was copied). The import pipeline enforces this gate, not the metadata plan.",
        "re_extraction_note": "Layer 8 re-extraction requires the original file. In reference mode, this means the source drive must be mounted. If unavailable, skip and log -- same behavior as copy-mode when originals have been deleted."
      }
    },

    "layer_7_sidecar_atomic_writes": {
      "purpose": "Sidecars now contain critical data (raw dumps, audit trail). Apply the same temp-verify-rename pattern used for file copies.",
      "import_pipeline_linkage": {
        "sidecar_as_manifest_entry": "Sidecar .json files written to .dadcam/sidecars/ MUST be tracked in the import manifest as entry_type='sidecar'. They are first-class eligible entries subject to full-hash verification and rescan, same as media files. If a sidecar fails verification, SAFE TO WIPE is blocked. This is enforced by the import pipeline (importplan.md A3), not by this metadata plan, but the sidecar writer must produce files that the manifest can discover and track.",
        "orphan_sidecars": "If a sidecar exists on the source device (e.g., camera-generated XML/THM files), the import pipeline includes them as eligible manifest entries. The metadata plan's sidecars (app-generated .dadcam/sidecars/*.json) are destination-side and are NOT on the source device, so they are not part of the source manifest. Do not confuse source-device sidecars (import concern) with app-generated sidecars (metadata concern)."
      },
      "current_code": "ingest/sidecar.rs uses std::fs::write() directly -- NOT atomic. No temp file, no fsync.",
      "write_pattern": [
        "1. Serialize sidecar to JSON string in memory.",
        "2. Validate: parse the JSON back to confirm it's valid. If parse fails, bug in serializer -- don't write corrupt data.",
        "3. Write to temp file: .dadcam/sidecars/.tmp_<clip_id>.json (same directory = same filesystem = atomic rename possible).",
        "4. fsync temp file.",
        "5. Atomic rename: .tmp_<clip_id>.json -> <clip_id>.json",
        "6. fsync parent directory."
      ],
      "why": "If the app crashes between writing raw dumps and writing the match audit, the sidecar could be half-written. With atomic writes, it's either the old complete version or the new complete version. Never a partial mess.",
      "read_pattern": {
        "missing_sidecar": "If sidecar file doesn't exist, all sidecar-sourced data is null. This is fine -- the DB has the core fields. Sidecar is enrichment, not source of truth for core data.",
        "corrupt_sidecar": "If sidecar exists but fails JSON parse, log error and treat as missing. Do NOT delete -- it might be recoverable. Mark clip for re-extraction."
      }
    },

    "layer_8_re_extraction_and_re_matching": {
      "purpose": "Background jobs that can re-run extraction or matching on existing clips. Needed when: exiftool tags are expanded, bundled_profiles.json is updated, matching algorithm is improved.",
      "re_extraction_job": {
        "trigger": "Manual (user clicks 'Rescan Library Metadata' in settings) or automatic (app detects pipeline_version bump).",
        "scope": "All clips in the library, or filtered by metadata_status.",
        "process": [
          "1. For each clip, check if rawExifDump exists in sidecar. If yes AND pipeline_version matches, skip (already extracted with current version).",
          "2. If missing or outdated: re-run exiftool and ffprobe on the original file.",
          "3. Update sidecar with new raw dumps. Re-parse fields. Atomic write.",
          "4. Reset metadata_status to 'extracted' (needs re-matching)."
        ],
        "requires_original": "YES. Re-extraction needs the original file. If file is missing (reference mode, drive disconnected), skip and log."
      },
      "re_matching_job": {
        "trigger": "Automatic when bundled_profiles.json version changes, or manual.",
        "scope": "All clips with winner='generic-fallback', or all clips if matcherVersion < current.",
        "process": [
          "1. For each clip, read inputSignature from sidecar matchAudit.",
          "2. Re-run matching algorithm against current profile database.",
          "3. If new winner != old winner AND new confidence > old confidence: update clip's profile assignment.",
          "4. Write new matchAudit to sidecar. Atomic write.",
          "5. If profile changed and clip has a proxy, mark proxy for regeneration (new transforms may apply)."
        ],
        "does_NOT_require_original": "No. Re-matching uses the stored inputSignature. This is the key benefit of the audit trail."
      }
    }
  },

  "gap_corrections_v32": {
    "summary": "14 implementation gaps identified during audit of v3.1 plan against actual codebase. Each resolved with specific decision.",
    "corrections": [
      {
        "id": "G1",
        "gap": "pipeline_version is referenced in Layer 8 but never defined",
        "resolution": "pipeline_version ALREADY EXISTS on the assets table (migration 1, column pipeline_version INTEGER). It is per-asset, not per-clip. Define constant METADATA_PIPELINE_VERSION: u32 = 1 in ingest/mod.rs. Bump when extraction logic changes. Re-extraction compares the clip's original asset's assets.pipeline_version against METADATA_PIPELINE_VERSION. If asset version < constant, re-extract. After successful re-extraction, update assets.pipeline_version = METADATA_PIPELINE_VERSION on the original asset. The sidecar also stores pipelineVersion in the rawExifDump and rawFfprobe sections so the version is captured alongside the data. No migration needed."
      },
      {
        "id": "G2",
        "gap": "Layer 0 says 'extraction_partial' but state machine has no such state",
        "resolution": "No extraction_partial state. If both tools fail: extraction_failed. If one tool fails, one succeeds: extracted (partial data noted in sidecar extractionStatus section). Layer 0 text corrected to say 'extracted with partial data'."
      },
      {
        "id": "G3",
        "gap": "No formula to convert raw score to confidence",
        "resolution": "Formula: confidence = min(score / 14.0, 0.95). Max possible score is 14.0 (+5 make+model, +3 codec+container, +3 folder, +2 resolution, +1 fps). Cap at 0.95 because profile-only matches never reach 1.0 certainty. Device matches use fixed values: USB=1.0, serial=0.95, make+model=0.6. Minimum threshold score 3.0 -> confidence 0.214.",
        "implementation": "fn score_to_confidence(score: f64) -> f64 { (score / 14.0).min(0.95) }"
      },
      {
        "id": "G4",
        "gap": "rotation_fix in profile schema but not in Rust TransformRules struct",
        "resolution": "Add rotation_fix: Option<bool> to TransformRules struct in camera/mod.rs. None=auto-detect from exiftool Rotation tag, Some(true)=always apply, Some(false)=never apply. Added in Step 2. Backward-compatible (Option deserializes missing fields as None)."
      },
      {
        "id": "G5",
        "gap": "field_order in profile schema but not in Rust TransformRules struct",
        "resolution": "Add field_order: Option<String> to TransformRules struct. None=auto-detect from ffprobe, Some('tff')=force top-field-first, Some('bff')=force bottom-field-first, Some('auto')=same as None. Added in Step 2."
      },
      {
        "id": "G6",
        "gap": "is_system/deletable/category not in bundled_profiles DB table",
        "resolution": "These are JSON-file-only fields. NOT synced to DB. sync_bundled_profiles() only reads slug, name, version, match_rules, transform_rules. is_system prevents deletion during sync and grays out delete button in UI. deletable is redundant with is_system for bundled profiles but exists for user profiles where deletion may still be prevented (e.g., profile assigned to devices). category is display-only for UI grouping. Add to the AppBundledProfile Rust struct (or a separate display struct): is_system: Option<bool>, deletable: Option<bool>, category: Option<String>. These are Option so they deserialize gracefully from profiles that don't have them. No migration needed."
      },
      {
        "id": "G7",
        "gap": "Extraction error detail storage location unspecified",
        "resolution": "Error detail stored in sidecar extractionStatus section. DB stores only the enum state (metadata_status), not error text. For extraction_failed where sidecar may not exist, error logged to app log and jobs.last_error. If clip is extracted with partial data (one tool failed), sidecar has the successful tool's raw dump and extractionStatus records which tool failed and why.",
        "extractionStatus_structure": {
          "status": "string -- matches metadata_status enum",
          "exiftool": {
            "success": "bool",
            "exitCode": "int",
            "error": "string or null -- stderr output if failed",
            "pipelineVersion": "int -- METADATA_PIPELINE_VERSION at extraction time"
          },
          "ffprobe": {
            "success": "bool",
            "exitCode": "int",
            "error": "string or null -- stderr output if failed",
            "pipelineVersion": "int -- METADATA_PIPELINE_VERSION at extraction time"
          },
          "extractedAt": "ISO8601 timestamp"
        }
      },
      {
        "id": "G8",
        "gap": "matcherVersion initial value undefined",
        "resolution": "Define MATCHER_VERSION: u32 = 1 in ingest/mod.rs. Version 1: current algorithm (weighted scoring, no reject rules). Version 2: after Step 4 (adds reject rules, minimum threshold 3.0, audit trail). Re-matching job queries clips where matchAudit.matcherVersion < MATCHER_VERSION."
      },
      {
        "id": "G9",
        "gap": "Concurrent extraction not addressed",
        "resolution": "Multiple clips CAN be extracted concurrently. State machine prevents double-extraction: UPDATE SET status='extracting' WHERE status='pending' (0 rows affected means another process claimed it). Temp filenames use clip_id so concurrent sidecar writes for different clips are safe. Re-extraction jobs limited to 4 concurrent clips (8 child processes total)."
      },
      {
        "id": "G10",
        "gap": "metadata_complete_at trigger mechanism unspecified",
        "resolution": "Event-driven. After each clip reaches terminal state (verified or extraction_failed), run: SELECT COUNT(*) FROM clips c JOIN ingest_files f ON c.id = f.clip_id JOIN ingest_manifest_entries me ON f.source_path = me.relative_path WHERE me.session_id = ? AND c.metadata_status NOT IN ('verified', 'extraction_failed'). If count = 0, UPDATE ingest_sessions SET metadata_complete_at = datetime('now') WHERE id = ? AND metadata_complete_at IS NULL. Note: clips does NOT have a session_id column -- the join through ingest_files and manifest_entries is required."
      },
      {
        "id": "G11",
        "gap": "discover_sample_files() mentioned as gap but not in any implementation step",
        "resolution": "Added to Step 8 scope. Implemented in camera/devices.rs. Algorithm: check known camera structures (DCIM/, AVCHD/BDMV/STREAM/, PRIVATE/AVCHD/) first, then walk root (max depth 3) and return 3 largest video files. Extensions: .mts, .m2ts, .mp4, .mov, .avi, .dv, .mpg, .mxf."
      },
      {
        "id": "G12",
        "gap": "No mechanism for soft match confirmation in device backflow",
        "resolution": "Soft matches (make+model, confidence <0.9) are NOT auto-applied. Returned as suggestions only. UI shows 'X clips auto-assigned. Y clips may be from this camera. [Assign All] [Review]'. If user clicks Assign All, app updates those clips in a transaction. If user clicks Review, they see the list and can accept/reject per-clip. No new DB column -- camera_device_uuid is only written when confirmed (auto or manual). Unconfirmed suggestions live only in the UI response.",
        "backflow_result_structs": {
          "BackflowResult": {
            "device_uuid": "String",
            "auto_assigned": "Vec<i64> -- clip IDs matched by serial/USB (applied immediately)",
            "suggested": "Vec<SuggestedMatch> -- clip IDs matched by model (NOT applied, presented to user)"
          },
          "SuggestedMatch": {
            "clip_id": "i64",
            "confidence": "f64",
            "match_method": "String -- e.g. 'make_model'"
          }
        }
      },
      {
        "id": "G13",
        "gap": "Proxy invalidation mechanism unclear",
        "resolution": "Use existing assets.pipeline_version column. When profile changes, set proxy asset's pipeline_version=0. Proxy generator finds stale proxies via WHERE pipeline_version < CURRENT. Old proxy remains playable until new one generated (no gap). Do NOT delete proxy file immediately."
      },
      {
        "id": "G14",
        "gap": "sensor object in profile schema not synced to DB",
        "resolution": "sensor is JSON-file-only display metadata. Stored in bundled_profiles.json per-profile. NOT synced to bundled_profiles DB table. Read at runtime from in-memory profile list for UI display. For user profiles, sensor info from device EXIF dump at registration (R3). No migration needed."
      }
    ],
    "migration_11_correction": {
      "issue": "Original plan says migration 11 adds media_type to clips. media_type ALREADY EXISTS on clips table (migration 1) with CHECK ('video','audio','image').",
      "resolution": "Migration 11 does NOT add media_type. It only adds: (1) metadata_status TEXT with CHECK constraint, default 'verified' for backfill, (2) metadata_complete_at TEXT on ingest_sessions. The 'unknown' value is dropped from DB CHECK -- use 'video' as conservative default. Sidecar mediaType field can store 'unknown' since it's just JSON.",
      "corrected_sql": "ALTER TABLE clips ADD COLUMN metadata_status TEXT CHECK (metadata_status IN ('pending','extracting','extracted','matching','matched','verified','extraction_failed')) DEFAULT 'verified'; ALTER TABLE ingest_sessions ADD COLUMN metadata_complete_at TEXT;"
    }
  },

  "what_changes_v32_vs_v31": [
    "Corrected 14 implementation gaps (G1-G14) identified during audit",
    "G1: Defined pipeline_version lifecycle (already exists on assets table)",
    "G2: Resolved extraction_partial vs extraction_failed conflict",
    "G3: Added score-to-confidence formula: min(score / 14.0, 0.95)",
    "G4: Added rotation_fix: Option<bool> to TransformRules struct",
    "G5: Added field_order: Option<String> to TransformRules struct",
    "G6: Clarified is_system/deletable/category are JSON-file-only",
    "G7: Defined error detail storage in sidecar extractionStatus section",
    "G8: Defined MATCHER_VERSION constant starting at 1",
    "G9: Specified concurrent extraction model with state machine safety",
    "G10: Defined metadata_complete_at trigger (event-driven)",
    "G11: Added discover_sample_files() to Step 8 scope",
    "G12: Clarified soft match is suggestion-only, not auto-applied",
    "G13: Defined proxy invalidation via assets.pipeline_version = 0",
    "G14: Clarified sensor is JSON-file-only display metadata",
    "Corrected migration 11: media_type already exists, dropped 'unknown' from DB"
  ],

  "what_changes_v31_vs_v3": [
    "Added layer 0b: outlier media handling (contract #4). Defines extraction, parsing, matching, and proxy behavior for audio-only, image, and unknown file types.",
    "Added media_type column to clips table (migration 11). Drives proxy generation branching and prevents audio-only files from being treated as extraction failures.",
    "Specified parsed field expectations per media type: which fields are populated vs null-and-expected for audio-only and image files.",
    "Specified generic-fallback behavior for outlier types: passthrough transforms, appropriate proxy formats (m4a for audio, resized JPEG for images).",
    "Specified that profile matching still runs on outlier types -- images CAN match camera profiles by make+model, which links photos to the same camera as video."
  ],

  "what_changes_v3_vs_v2": [
    "Added 'existing_code_reality' section documenting what ACTUALLY exists in the codebase.",
    "Added 'v3_corrections' section with 8 specific fixes (C1-C8).",
    "Fixed step 1: targets ingest/mod.rs:1271 (not camera/matcher.rs) for fallback change.",
    "Fixed generic-fallback seeding: goes into bundled_profiles.json (not canonical.json).",
    "Removed migration 12: App DB camera_devices already has profile_type + profile_ref.",
    "Fixed deinterlace type: uses null (None in Option<bool>) for auto-detect, no type change needed.",
    "Noted that weighted scoring already exists in score_match_rules(). Step 4 now only adds reject rules + audit trail.",
    "Fixed all references from 'canonical.json' to 'bundled_profiles.json' as the primary profile source.",
    "Added matchSource field to audit trail to distinguish device match from profile match.",
    "Layer 4 schema gaps section rewritten to reflect reality (only sample_exif_path is genuinely missing)."
  ],

  "what_changes_v2_vs_v1": [
    "Added layer 0: raw dump capture. This is the foundation. Capture everything, parse later.",
    "Added layer 6: state machine for metadata extraction. Crash recovery, completeness tracking.",
    "Added layer 7: atomic sidecar writes. Same temp-verify-rename as file copies.",
    "Added layer 8: re-extraction and re-matching jobs. Background processing for upgrades.",
    "Expanded matching algorithm with reject rules (negative matching) and multi-phase scoring.",
    "Changed exiftool approach: from cherry-picking 9 tags to capturing FULL dump with -j -G -n.",
    "Added confidence meaning scale (1.0 to 0.1) with clear thresholds.",
    "Added cross-validation requirement to verification workflow.",
    "Added metadata_status column (migration 11) for per-clip pipeline tracking.",
    "Added metadata_complete_at to ingest_sessions for completeness gate.",
    "Expanded layer 4 from stub to complete flow: R1-R8 registration, B1-B6 backflow, F1-F4 forward flow."
  ],

  "implementation_order": [
    {
      "step": 1,
      "name": "Generic fallback profile + atomic sidecar writes",
      "scope": "Add generic-fallback to bundled_profiles.json. Synced to App DB via existing sync_bundled_profiles(). Change fallback in resolve_profile_from_app_db(). Implement temp-verify-rename for sidecar writes.",
      "files_touched": [
        "resources/cameras/bundled_profiles.json -- add generic-fallback entry",
        "src-tauri/src/ingest/mod.rs -- line 1271: change ('none', '') to ('bundled', 'generic-fallback')",
        "src-tauri/src/ingest/sidecar.rs -- replace std::fs::write() with atomic temp-fsync-rename"
      ],
      "migration": "None",
      "risk": "Low",
      "why_first": "Generic fallback is the safety net. Everything else builds on 'every clip always has a profile'. Atomic writes protect the sidecars that all subsequent layers depend on."
    },
    {
      "step": 2,
      "name": "Raw dump capture (exiftool + ffprobe)",
      "scope": "Change exiftool to -j -G -n (full dump). Change ffprobe to capture extended fields. Store raw outputs in sidecar. Parse structured fields from dumps instead of from tool-specific code.",
      "files_touched": [
        "src-tauri/src/metadata/exiftool.rs -- switch from 9-tag request to full -j -G -n dump",
        "src-tauri/src/metadata/ffprobe.rs -- add extended stream fields to FFprobeStream struct",
        "src-tauri/src/metadata/mod.rs -- expand MediaMetadata with extended fields",
        "src-tauri/src/ingest/sidecar.rs -- add rawExifDump and rawFfprobe sections"
      ],
      "migration": "None",
      "risk": "Low -- existing fields still parsed, just from a richer source"
    },
    {
      "step": 3,
      "name": "Metadata extraction state machine",
      "scope": "Add metadata_status column to clips. Add metadata_complete_at to ingest_sessions. Implement state transitions in ingest pipeline. Add crash recovery on app launch.",
      "files_touched": [
        "src-tauri/src/db/migrations.rs -- migration 11",
        "src-tauri/src/ingest/mod.rs -- state transitions during ingest"
      ],
      "migration": "Migration 11 -- add metadata_status to clips (DEFAULT 'verified' for backfill; app code sets 'pending' on new inserts), metadata_complete_at to ingest_sessions. Note: media_type already exists on clips (migration 1), no change needed.",
      "risk": "Low"
    },
    {
      "step": 4,
      "name": "Match audit trail + reject rules",
      "scope": "Add reject_codec/reject_container/reject_model checking BEFORE existing score_match_rules(). Add minimum score threshold. Return all candidates from matcher. Write matchAudit section to sidecar with matchSource field.",
      "files_touched": [
        "src-tauri/src/ingest/mod.rs -- add reject phase before score_match_rules(), add threshold check, return candidates",
        "src-tauri/src/ingest/sidecar.rs -- add matchAudit section to SidecarData"
      ],
      "migration": "None",
      "risk": "Medium -- matching behavior changes, need to verify no regressions",
      "note": "Weighted scoring is NOT changed -- it already exists and works correctly."
    },
    {
      "step": 5,
      "name": "Populate and verify bundled_profiles.json",
      "scope": "Build tier 1 profiles (7 profiles). Verify each against real samples. Run cross-validation. Make bundled_profiles.json the single source (update legacy canonical.json/bundled.rs to read from same file or deprecate).",
      "files_touched": [
        "resources/cameras/bundled_profiles.json -- add verified profiles",
        "src-tauri/src/camera/bundled.rs -- update to read from bundled_profiles.json or deprecate",
        "resources/cameras/canonical.json -- deprecate or symlink to bundled_profiles.json"
      ],
      "migration": "None",
      "risk": "Medium -- need real sample files"
    },
    {
      "step": 6,
      "name": "Re-matching background job",
      "scope": "Implement re-matching job that scans generic-fallback clips using stored inputSignature. Triggered when bundled_profiles.json version changes.",
      "files_touched": ["src-tauri/src/jobs/", "src-tauri/src/ingest/mod.rs"],
      "migration": "None",
      "risk": "Low"
    },
    {
      "step": 7,
      "name": "Re-extraction background job",
      "scope": "Implement re-extraction job for existing libraries. Triggered manually or by pipeline_version bump.",
      "files_touched": ["src-tauri/src/jobs/", "src-tauri/src/ingest/sidecar.rs"],
      "migration": "None",
      "risk": "Low"
    },
    {
      "step": 8,
      "name": "Device registration EXIF dump + auto-profile",
      "scope": "During device registration (R3-R4): run full exiftool+ffprobe on sample files from the camera. Auto-match to a profile using match_bundled_profile_rules() + match_app_profile_rules(). Store dumps in ~/.dadcam/device_dumps/<uuid>.json. Pre-fill registration form. Implement discover_sample_files(mount_point) in camera/devices.rs that returns 1-3 representative video files from a mounted volume (check DCIM/, AVCHD/BDMV/STREAM/, PRIVATE/AVCHD/ first, then walk root max depth 3 and return 3 largest video files).",
      "files_touched": [
        "src-tauri/src/camera/devices.rs -- add registration flow with EXIF dump + auto-match",
        "src-tauri/src/metadata/exiftool.rs -- reuse full dump mode",
        "src-tauri/src/metadata/ffprobe.rs -- reuse extended extraction"
      ],
      "migration": "None needed. App DB camera_devices already has profile_type + profile_ref. Store dump at conventional path instead of adding column.",
      "risk": "Low -- reuses layer 0 extraction code"
    },
    {
      "step": 9,
      "name": "Forward flow: device matching during ingest",
      "scope": "Verify resolve_stable_camera_refs() correctly propagates device.profile_type + device.profile_ref to clip columns. Add matchSource to sidecar cameraMatch section.",
      "files_touched": [
        "src-tauri/src/ingest/mod.rs -- verify device -> clip profile propagation",
        "src-tauri/src/ingest/sidecar.rs -- add matchSource field"
      ],
      "migration": "None -- uses existing migration 7 columns",
      "risk": "Medium -- touches ingest pipeline"
    },
    {
      "step": 10,
      "name": "Backflow: re-match existing clips on device registration",
      "scope": "After insert_device(), scan all clips with camera_device_uuid=NULL. Match by serial, then by ingest session USB fingerprint, then by make+model. Update clips in transaction. Re-write sidecars. Invalidate proxies if profile changed. Report results to UI.",
      "files_touched": [
        "src-tauri/src/camera/devices.rs -- add backflow scan after registration",
        "src-tauri/src/ingest/mod.rs -- matching functions reuse",
        "src-tauri/src/ingest/sidecar.rs -- sidecar updates"
      ],
      "migration": "None",
      "risk": "Medium -- batch updates to existing clips, need transaction safety"
    },
    {
      "step": 11,
      "name": "Backflow: re-match on profile add/update",
      "scope": "When bundled_profiles.json version changes or user creates/edits a profile: (a) check registered devices with profile_type='none' -- offer to assign, (b) re-match generic-fallback clips using stored inputSignature, (c) re-check devices' stored EXIF dumps against new profiles.",
      "files_touched": [
        "src-tauri/src/db/app_schema.rs -- detect profile version changes",
        "src-tauri/src/ingest/mod.rs -- re-matching logic",
        "src-tauri/src/jobs/ -- background job definition"
      ],
      "migration": "None",
      "risk": "Low -- uses stored data, no file access needed"
    }
  ],

  "the_sharp_idea": {
    "summary": "Dad Cam is a memory machine. It works on any video because memories come from everywhere -- dad's camcorder, mom's phone, the GoPro from vacation, that weird DVD camcorder from 2006, a VHS tape digitized at Costco, a screen recording of a FaceTime call. The metadata and profile system makes each of those look and play its best, but NONE of them are blocked or degraded if we don't recognize the source. That's what makes it gold standard: it works for the person who just dumps a folder of mystery files and wants to watch their life.",
    "simple_user_experience": "Import folder. Everything plays. Interlaced stuff gets deinterlaced. Rotated stuff gets rotated. No settings. No camera selection. No questions. It just works.",
    "pro_user_experience": "Register your cameras. Get fleet tracking. Get camera-specific color and deinterlace. Export audit trails. But none of this is required.",
    "technical_guarantee": "Every clip always has: a profile (at minimum generic-fallback), metadata (at minimum filename + size), a sidecar (at minimum raw dumps), and an audit trail (at minimum 'no match, using generic'). Zero clips in limbo. Zero clips with incomplete state. Same standard as the import tool: if we touched it, we tracked it."
  }
}
